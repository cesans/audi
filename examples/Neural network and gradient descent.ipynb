{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from pyaudi import gdual\n",
    "from pyaudi import sin, cos, tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent to train a neural network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the architecture of the network:\n",
    "\n",
    "    Inputs: 3\n",
    "    Hidden layers: 2 with 5 units/layer\n",
    "    Outputs: 1\n",
    "\n",
    "We will need the first order derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_units = [3, 5, 5, 1]\n",
    "order = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symbolic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create symbolic variables for the weights with values drawn from $\\mathcal N(0,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_weights(n_units, order):\n",
    "\n",
    "    weights = []\n",
    "\n",
    "    for layer in range(1, len(n_units)):\n",
    "        weights.append([])\n",
    "        for unit in range(n_units[layer]):\n",
    "            weights[-1].append([])\n",
    "            for prev_unit in range(n_units[layer-1]):                \n",
    "                symname = 'w_{{({0},{1},{2})}}'.format(layer, unit, prev_unit)\n",
    "                w = gdual(np.random.randn(), symname , order)\n",
    "                weights[-1][-1].append(w)\n",
    "          \n",
    "    return weights\n",
    "\n",
    "weights = initialize_weights(n_units, order)                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the biases, initialized to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_biases(n_units, order):\n",
    "\n",
    "    biases = []\n",
    "\n",
    "    for layer in range(1, len(n_units)):\n",
    "        biases.append([])\n",
    "        for unit in range(n_units[layer]):\n",
    "            symname = 'b_{{({0},{1})}}'.format(layer, unit)\n",
    "            b = gdual(1, symname , order)\n",
    "            biases[-1].append(b)\n",
    "            \n",
    "    return biases\n",
    "\n",
    "biases = initialize_biases(n_units, order)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network as a gdual expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function which output is the expression (*gdual*) corresponding to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def N_f(inputs, w, b):\n",
    "        \n",
    "    prev_layer_outputs = inputs\n",
    "    \n",
    "    #Hidden layers\n",
    "    for layer in range(len(weights)):\n",
    "        \n",
    "        this_layer_outputs = []\n",
    "        \n",
    "        for unit in range(len(weights[layer])):\n",
    "            \n",
    "            unit_output = 0\n",
    "            unit_output += b[layer][unit]\n",
    "            \n",
    "            for prev_unit,prev_output in enumerate(prev_layer_outputs):\n",
    "                unit_output += w[layer][unit][prev_unit] * prev_output\n",
    "            \n",
    "            if layer != len(weights)-1:\n",
    "                unit_output = tanh(unit_output)\n",
    "                \n",
    "            this_layer_outputs.append(unit_output)\n",
    "            \n",
    "        prev_layer_outputs = this_layer_outputs\n",
    "\n",
    "    return prev_layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new function can be used to compute the output of the network given any input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(x) = 4.047941970504932\n"
     ]
    }
   ],
   "source": [
    "x1 = 1\n",
    "x2 = 2\n",
    "x3 = 4\n",
    "\n",
    "N = N_f([x1,x2, x3], weights, biases)[0]\n",
    "print('N(x) = {0}'.format(N.constant_cf))\n",
    "#N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case the desired output of the network will be: $y(\\mathcal x)= x_1x_2 + 0.5x_3 +2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 6.0\n"
     ]
    }
   ],
   "source": [
    "def y_f(x):\n",
    "    return x[0]*x[1] + 0.5*x[2] + 2\n",
    "\n",
    "y = y_f([x1,x2,x3])\n",
    "print('y = {0}'.format(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process will seek to minimize a loss function corresponding to the quadratic error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 3.810530550516167\n"
     ]
    }
   ],
   "source": [
    "def loss_f(N,y):\n",
    "    return (N-y)**2\n",
    "\n",
    "loss = loss_f(N, y)\n",
    "print('loss = {0}'.format(loss.constant_cf))\n",
    "#loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function loss_f accepts a gdual (N) and a float (y) and the output still a gdual, which will make it possible to compute its derivatives wrt any of the parameters of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_{(2,4,0)}\n",
      "w_{(2,4,1)}\n",
      "w_{(2,4,2)}\n",
      "w_{(2,4,3)}\n",
      "w_{(2,4,4)}\n",
      "w_{(3,0,0)}\n",
      "w_{(3,0,1)}\n",
      "w_{(3,0,2)}\n",
      "w_{(3,0,3)}\n",
      "w_{(3,0,4)}\n"
     ]
    }
   ],
   "source": [
    "for symbol in loss.symbol_set[-10:]:\n",
    "    print(symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the weights with gradient descent using the first order derivatives of the loss function with respect to the weights (and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GD_update(loss, w, b, lr):\n",
    "    \n",
    "    #Update weights\n",
    "    for layer in range(len(w)):\n",
    "        for unit in range(len(w[layer])):\n",
    "            for prev_unit in range(len(w[layer][unit])):\n",
    "                \n",
    "                weight = w[layer][unit][prev_unit]\n",
    "                if weight.symbol_set[0] in loss.symbol_set:\n",
    "                    symbol_idx = loss.symbol_set.index(weight.symbol_set[0])\n",
    "                    d_idx = [0]*loss.symbol_set_size                                                      \n",
    "                    d_idx[symbol_idx] = 1\n",
    "                    \n",
    "                    # eg. if d_idx = [1,0,0,0,...] get get the derivatives of loss wrt\n",
    "                    # the first symbol (variable) in loss.symbol_set\n",
    "                    w[layer][unit][prev_unit] -= loss.get_derivative(d_idx) * lr\n",
    "\n",
    "    #Update biases\n",
    "    for i in range(len(b)):\n",
    "        for j in range(len(b[layer])):\n",
    "            \n",
    "                bias = b[layer][unit]\n",
    "                if bias.symbol_set[0] in loss.symbol_set:\n",
    "                    symbol_idx = loss.symbol_set.index(bias.symbol_set[0])\n",
    "                    d_idx = [0]*loss.symbol_set_size                    \n",
    "                    d_idx[symbol_idx] = 1\n",
    "                    b[layer][unit] -= loss.get_derivative(d_idx) * lr\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After one GD step the loss function decrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2.712243365941881\n"
     ]
    }
   ],
   "source": [
    "weights, biases = GD_update(loss, weights, biases, 0.01) \n",
    "\n",
    "N = N_f([x1,x2,x3], weights, biases)[0]\n",
    "loss = loss_f(N, y)\n",
    "print('loss = {0}'.format(loss.constant_cf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for several data points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = -1+2*np.random.rand(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, training loss: 0.21947505586206764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f176b6d10b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAESCAYAAAAIfCk9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSiEhIiKD+v+dc03Hw5AUUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f176b716668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history = []\n",
    "\n",
    "weights = initialize_weights(n_units, order)                \n",
    "biases = initialize_biases(n_units, order)            \n",
    "\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for e in range(epochs):\n",
    "        \n",
    "    #Just records the error at the beginning of this step\n",
    "    epoch_loss = []\n",
    "    for xi in X:\n",
    "        N = N_f(xi, weights, biases)[0]\n",
    "        loss = loss_f(N, y_f(xi))\n",
    "        epoch_loss.append(loss.constant_cf)    \n",
    "        \n",
    "    loss_history.append(np.mean(epoch_loss))\n",
    "    \n",
    "    #Updates the weights\n",
    "    for xi in X:\n",
    "        N = N_f(xi, weights, biases)[0]\n",
    "        loss = loss_f(N, y_f(xi))\n",
    "        weights, biases = GD_update(loss, weights, biases, 0.001)     \n",
    "\n",
    "print('epoch {0}, training loss: {1}'.format(e, loss_history[-1]))        \n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
